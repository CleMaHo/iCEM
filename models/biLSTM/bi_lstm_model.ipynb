{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import time\n",
    "import torch.utils.data as data_utils\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pandas as pd\n",
    "import random\n",
    "from scipy.optimize import minimize\n",
    "from tqdm import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/home/lukas-zeh/Documents/GNN_CableSimulation/simulationData/data/combined_dataset_NEW_METHOD_20k.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimulationDataset(data_utils.Dataset):\n",
    "    def __init__(self, file_path):\n",
    "        # Load the data from the provided file path\n",
    "        data = np.load(file_path)\n",
    "        \n",
    "        # Extract and preprocess end-effector (EE) position and velocity\n",
    "        self.EE_pos = torch.tensor(data['EE_pos'][:, [0, 1, 2, 4]], dtype=torch.float32)  # Shape: (_, 4)\n",
    "        self.EE_vel = torch.tensor(data['EE_vel'][:, [0, 1, 2, 5]], dtype=torch.float32) * 0.02  # Shape: (_, 4)\n",
    "        \n",
    "        # Extract cable positions and initialize noisy version\n",
    "        self.cable_pos = torch.tensor(data['cable_pos'], dtype=torch.float32)  # Shape: (_, 50, 3)\n",
    "        self.cable_pos_noise = torch.tensor(data['cable_pos'], dtype=torch.float32)  # Shape: (_, 50, 3)\n",
    "        \n",
    "        # Add noise to the data\n",
    "        self.add_noise(std_EE=0, std_vel=0, std_cable=0.001)\n",
    "        \n",
    "        # Precompute relative positions of cable markers with respect to the EE\n",
    "        self.relativ_cable_pos = self.precompute_relative_positions_tEE()\n",
    "\n",
    "        # Calculate cable velocity using noisy data\n",
    "        self.cable_vel = torch.diff(self.cable_pos_noise, dim=0)  # Shape: (_, 50, 3)\n",
    "\n",
    "        # Compute normalization statistics for EE position, velocity, and cable velocity\n",
    "        self.EE_pos_mean = self.EE_pos.mean(dim=0)\n",
    "        self.EE_pos_std = self.EE_pos.std(dim=0)\n",
    "        self.EE_vel_mean = self.EE_vel.mean(dim=0)  # Shape: (D,)\n",
    "        self.EE_vel_std = self.EE_vel.std(dim=0)    # Shape: (D,)\n",
    "        self.l2_relativ_norm_cable_pos = torch.norm(self.relativ_cable_pos, dim=2, keepdim=True)\n",
    "        self.cable_vel_mean = self.cable_vel.mean(dim=(0, 1), keepdim=True)  # Global mean\n",
    "        self.cable_vel_std = self.cable_vel.std(dim=(0, 1), keepdim=True)    # Global std\n",
    "\n",
    "        eps = 1e-9  # Small epsilon to avoid division by zero\n",
    "        # Normalize the data\n",
    "        self.EE_pos_normalized = (self.EE_pos - self.EE_pos_mean) / (self.EE_pos_std + eps)\n",
    "        self.EE_vel_normalized = (self.EE_vel - self.EE_vel_mean) / (self.EE_vel_std + eps)\n",
    "        self.cable_pos_normalized = self.relativ_cable_pos / (self.l2_relativ_norm_cable_pos + eps)\n",
    "        self.cable_vel_normalized = (self.cable_vel - self.cable_vel_mean) / (self.cable_vel_std + eps)\n",
    "\n",
    "        # Save normalization statistics to a JSON file for later use\n",
    "        stats = {\n",
    "            \"EE_vel_mean\": self.EE_vel_mean.tolist(),\n",
    "            \"EE_vel_std\": self.EE_vel_std.tolist(),\n",
    "            \"cable_vel_mean\": self.cable_vel_mean.tolist(),\n",
    "            \"cable_vel_std\": self.cable_vel_std.tolist()\n",
    "        }\n",
    "        with open(\"normalization_stats.json\", \"w\") as f:\n",
    "            json.dump(stats, f, indent=4)\n",
    "\n",
    "        self.num_markers = 9  # Number of markers selected for processing\n",
    "\n",
    "        # Debug outputs for verification\n",
    "        print(\"EE_pos normalized Shape\", self.EE_pos_normalized.shape)  # Expected: (_, 4)\n",
    "        print(\"EE_vel normalized Shape\", self.EE_vel_normalized.shape)  # Expected: (_, 4)\n",
    "        print(\"cable_pos normalized Shape\", self.cable_pos_normalized.shape)  # Expected: (_, 50, 3)\n",
    "\n",
    "    def precompute_relative_positions(self):\n",
    "        \"\"\"\n",
    "        Precomputes relative positions of cable markers with respect to the EE position\n",
    "        and differences between adjacent markers.\n",
    "        \"\"\"\n",
    "        T = self.cable_pos_noise.shape[0]  # Number of time steps (samples)\n",
    "        all_rel_positions = []\n",
    "\n",
    "        for t in range(T):\n",
    "            # Select marker coordinates (x, y)\n",
    "            coords = self.cable_pos_noise[t, :, :2]  # Shape: (50, 2)\n",
    "            coords = coords[6:-3]  # Filter out unwanted markers\n",
    "            coords = coords[::5]  # Select every 5th marker => 9 markers\n",
    "\n",
    "            # Compute differences between adjacent markers\n",
    "            relative_DLO = coords[1:] - coords[:-1]  # Shape: (8, 2)\n",
    "\n",
    "            # Compute the first marker's position relative to the EE position\n",
    "            EE_pos = self.EE_pos[t, :2]  # Shape: (2,)\n",
    "            first_marker_relative_to_EE = coords[0] - EE_pos.unsqueeze(0)  # Shape: (1, 2)\n",
    "\n",
    "            # Combine relative positions into a single tensor\n",
    "            rel_coords_t = torch.cat((first_marker_relative_to_EE, relative_DLO), dim=0)\n",
    "            all_rel_positions.append(rel_coords_t)\n",
    "\n",
    "        # Stack all time steps into a 3D tensor: (T, 9, 2)\n",
    "        precomputed_rel_positions = torch.stack(all_rel_positions, dim=0)\n",
    "        return precomputed_rel_positions\n",
    "\n",
    "    def precompute_relative_positions_tEE(self):\n",
    "        \"\"\"\n",
    "        Precomputes relative positions of cable markers with respect to the EE position.\n",
    "        \"\"\"\n",
    "        T = self.cable_pos_noise.shape[0]  # Number of time steps\n",
    "        all_rel_positions = []  # List to store relative positions for all time steps\n",
    "\n",
    "        for t in range(T):\n",
    "            # Select marker coordinates (x, y)\n",
    "            coords = self.cable_pos_noise[t, :, :2]  # Shape: (50, 2)\n",
    "            coords = coords[6:-3]  # Filter out unwanted markers\n",
    "            coords = coords[::5]  # Select every 5th marker => 9 markers\n",
    "\n",
    "            # Compute relative positions with respect to the EE position\n",
    "            EE_pos = self.EE_pos[t, :2]  # Shape: (2,)\n",
    "            rel_positions = coords - EE_pos.unsqueeze(0)  # Shape: (9, 2)\n",
    "\n",
    "            all_rel_positions.append(rel_positions)  # Add to list\n",
    "\n",
    "        # Stack all time steps into a 3D tensor: (T, 9, 2)\n",
    "        precomputed_rel_positions = torch.stack(all_rel_positions, dim=0)\n",
    "        return precomputed_rel_positions\n",
    "\n",
    "    def get_local_relativ_positions(self, idx):\n",
    "        \"\"\"\n",
    "        Returns the local relative 2D positions of cable markers, including\n",
    "        the first marker relative to the EE position.\n",
    "        \"\"\"\n",
    "        coords = self.cable_pos_noise[idx, :, :2]  # Only x, y coordinates\n",
    "        coords = coords[6:-3]  # Filter markers\n",
    "        coords = coords[::5]  # Select markers (every 5th)\n",
    "\n",
    "        # Calculate differences between adjacent markers\n",
    "        relative_DLO = coords[1:] - coords[:-1]\n",
    "\n",
    "        # First marker relative to EE position\n",
    "        EE_pos = self.EE_pos[idx, :2]  # Only x, y coordinates of EE position\n",
    "        first_marker_relative_to_EE = coords[0] - EE_pos.unsqueeze(0)\n",
    "\n",
    "        # Combine: [First marker relative to EE, then differences]\n",
    "        relative_DLO = torch.cat((first_marker_relative_to_EE, relative_DLO), dim=0)\n",
    "\n",
    "        return relative_DLO\n",
    "\n",
    "    def add_noise(self, std_EE=0.001, std_vel=0.001, std_cable=0.002):\n",
    "        \"\"\"\n",
    "        Adds Gaussian noise to EE position, velocity, and cable positions.\n",
    "        \"\"\"\n",
    "        noise_EE = torch.normal(0, std_EE, size=self.EE_pos.shape)\n",
    "        noise_vel = torch.normal(0, std_vel, size=self.EE_vel.shape)\n",
    "        noise_cable = torch.normal(0, std_cable, size=self.cable_pos.shape)\n",
    "\n",
    "        self.EE_pos += noise_EE\n",
    "        self.EE_vel += noise_vel\n",
    "        self.cable_pos_noise += noise_cable\n",
    "\n",
    "    def get_norm_absolute_coords(self, idx):\n",
    "        \"\"\"\n",
    "        Returns the normalized absolute coordinates of selected cable markers.\n",
    "        \"\"\"\n",
    "        absolute_coords = self.cable_pos_normalized[idx, :, :2]\n",
    "        absolute_coords = absolute_coords[6:-3]\n",
    "        absolute_coords = absolute_coords[::5]\n",
    "\n",
    "        return absolute_coords.flatten()\n",
    "\n",
    "    def get_absolute_coords(self, idx):\n",
    "        \"\"\"\n",
    "        Returns the absolute coordinates of selected cable markers.\n",
    "        \"\"\"\n",
    "        absolute_coords = self.cable_pos[idx, :, :2]\n",
    "        absolute_coords = absolute_coords[6:-3]\n",
    "        absolute_coords = absolute_coords[::5]\n",
    "\n",
    "        return absolute_coords.flatten()\n",
    "\n",
    "    def get_norm_marker_velocity(self, idx):\n",
    "        \"\"\"\n",
    "        Calculates the normalized velocity of the markers.\n",
    "        :param idx: Index of the current time step\n",
    "        :return: Normalized velocity (9 markers, 2D)\n",
    "        \"\"\"\n",
    "        if idx == 0:\n",
    "            return torch.zeros(self.num_markers, 2)\n",
    "\n",
    "        norm_velocity = self.cable_vel_normalized[idx, :, :2]\n",
    "        norm_velocity = norm_velocity[6:-3]\n",
    "        norm_velocity = norm_velocity[::5]\n",
    "\n",
    "        return norm_velocity\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the length of the dataset (number of samples).\n",
    "        \"\"\"\n",
    "        return len(self.EE_pos) - 2\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Returns the input and target data for a given index.\n",
    "        \"\"\"\n",
    "        # Current robot state (position and velocity)\n",
    "        current_robot_state_pos = self.EE_pos_normalized[idx].unsqueeze(0).repeat(self.num_markers, 1)\n",
    "        current_robot_state_vel = self.EE_vel_normalized[idx].unsqueeze(0).repeat(self.num_markers, 1)\n",
    "        current_robot_state = torch.cat((current_robot_state_pos, current_robot_state_vel), dim=1)\n",
    "\n",
    "        # Current relative cable state\n",
    "        current_relative_dlo_state = self.cable_pos_normalized[idx]\n",
    "\n",
    "        # Current relative cable velocity\n",
    "        if idx > 0:\n",
    "            current_relative_dlo_velocity = self.get_norm_marker_velocity(idx - 1)\n",
    "        else:\n",
    "            current_relative_dlo_velocity = torch.zeros(self.num_markers, 2)\n",
    "\n",
    "        # Combine cable state and velocity\n",
    "        current_dlo_state = torch.cat((current_relative_dlo_state, current_relative_dlo_velocity), dim=1)\n",
    "\n",
    "        # Combine robot state and cable state into inputs\n",
    "        inputs = torch.cat((current_robot_state, current_dlo_state), dim=1)\n",
    "\n",
    "        # Target is the normalized velocity of the markers\n",
    "        target = self.get_norm_marker_velocity(idx).view(self.num_markers, 2)\n",
    "\n",
    "        return inputs, target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "#check for gpu\n",
    "if torch.cuda.is_available():\n",
    "   device = torch.device(\"cuda\")\n",
    "   x = torch.ones(1, device=device)\n",
    "   print (x)\n",
    "#if else torch.backends.cuda.is_available:\n",
    "else:\n",
    "   device = torch.device(\"cpu\")\n",
    "   print (\"MPS device not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiMarkerLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    A PyTorch LSTM-based model for processing multi-marker data.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 marker_dim: int = 12,  # Dimensionality of each marker's input features\n",
    "                 window_size: int = 5,  # Deprecated, not used in this implementation\n",
    "                 hidden_size: int = 64,  # Number of hidden units in the LSTM\n",
    "                 num_markers: int = 9,  # Number of markers being processed\n",
    "                 output_dim: int = 2,  # Dimensionality of the output for each marker\n",
    "                 num_layers: int = 3):  # Number of LSTM layers\n",
    "\n",
    "        super(MultiMarkerLSTM, self).__init__()\n",
    "\n",
    "        # Save model parameters\n",
    "        self.num_markers = num_markers\n",
    "        self.marker_dim = marker_dim\n",
    "        self.window_size = window_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.bidirectional = True  # Use bidirectional LSTM\n",
    "        self.num_directions = 2  # Forward + Backward directions for bidirectional LSTM\n",
    "\n",
    "        # Fully connected layer to map LSTM outputs to the desired output dimension\n",
    "        self.fc = nn.Linear(hidden_size * self.num_directions, output_dim)\n",
    "\n",
    "        # LSTM layer\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.marker_dim,  # Input feature size for each marker\n",
    "            hidden_size=hidden_size,  # Number of hidden units in the LSTM\n",
    "            num_layers=num_layers,  # Number of LSTM layers\n",
    "            batch_first=True,  # Input tensor shape: (batch_size, seq_len, input_size)\n",
    "            bidirectional=self.bidirectional  # Use bidirectional LSTM\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of the model.\n",
    "\n",
    "        Parameters:\n",
    "        x: Tensor of shape (batch_size, num_markers, marker_dim)\n",
    "           - batch_size: Number of samples in the batch\n",
    "           - num_markers: Number of markers being processed\n",
    "           - marker_dim: Dimensionality of each marker's input features\n",
    "\n",
    "        Returns:\n",
    "        output: Tensor of shape (batch_size, num_markers, output_dim)\n",
    "                - output_dim: Dimensionality of the output for each marker\n",
    "        \"\"\"\n",
    "\n",
    "        # Pass the input through the LSTM layer\n",
    "        # lstm_out: Tensor of shape (batch_size, num_markers, hidden_size * num_directions)\n",
    "        # h_n, c_n: Hidden and cell states (not used here)\n",
    "        lstm_out, (h_n, c_n) = self.lstm(x)\n",
    "\n",
    "        # Pass the LSTM output through the fully connected layer\n",
    "        # Maps the LSTM output to the desired output dimension\n",
    "        output = self.fc(lstm_out)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters:  3707906\n"
     ]
    }
   ],
   "source": [
    "# Define the expected input size for the model\n",
    "expected_input_size = 12\n",
    "\n",
    "# Define the hidden size for the LSTM and initialize the model\n",
    "hidden_size = 256\n",
    "model = MultiMarkerLSTM(hidden_size=hidden_size, num_layers=3)\n",
    "\n",
    "# Move the model to the specified device (CPU or GPU)\n",
    "model = model.to(device)\n",
    "\n",
    "# Calculate and print the number of trainable parameters in the model\n",
    "number_of_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"Number of parameters: \", number_of_parameters)\n",
    "\n",
    "# Define the loss function (Mean Squared Error Loss)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Define the optimizer (Adam optimizer with learning rate and weight decay)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-5)\n",
    "\n",
    "# Training loop parameters\n",
    "epochs = 1  # Number of epochs to train the model\n",
    "train_losses = []  # List to store training losses for each epoch\n",
    "val_losses = []  # List to store validation losses for each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EE_pos normalized Shape torch.Size([5000000, 4])\n",
      "EE_vel normalized Shape torch.Size([5000000, 4])\n",
      "cable_pos normalized Shape torch.Size([5000000, 9, 2])\n",
      "Train size: 3999998, Validation size: 1000000\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the SimulationDataset using the provided file path\n",
    "dataset = SimulationDataset(file_path)\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_size = int(0.8 * len(dataset))  # 80% of the dataset for training\n",
    "val_size = len(dataset) - train_size  # Remaining 20% for validation\n",
    "\n",
    "# Define indices for training and validation splits\n",
    "train_indices = range(0, train_size)  # Indices for the training set\n",
    "val_indices = range(train_size, len(dataset))  # Indices for the validation set\n",
    "\n",
    "# Create subsets for training and validation datasets\n",
    "train_dataset = Subset(dataset, train_indices)  # Training subset\n",
    "val_dataset = Subset(dataset, val_indices)  # Validation subset\n",
    "\n",
    "# Create DataLoaders for training and validation datasets\n",
    "# DataLoader helps in batching, shuffling, and loading data efficiently\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)  # Shuffle training data\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)  # Do not shuffle validation data\n",
    "\n",
    "# Print the sizes of the training and validation datasets\n",
    "print(f\"Train size: {len(train_dataset)}, Validation size: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for epoch in range(epochs):\n",
    "#     model.train()  # Set the model to training mode\n",
    "#     train_loss = 0  # Initialize training loss for the epoch\n",
    "#     train_loader_tqdm = tqdm(train_loader, desc=f\"Training Epoch {epoch + 1}/{epochs}\", leave=True)  # Progress bar for training\n",
    "\n",
    "#     for batch_idx, (inputs, targets) in enumerate(train_loader_tqdm):\n",
    "#         # Move inputs and targets to the specified device (CPU or GPU)\n",
    "#         inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "#         # Check if the input size matches the expected size\n",
    "#         if inputs.size(-1) != expected_input_size:\n",
    "#             raise ValueError(f\"Expected input size {expected_input_size}, but got {inputs.size(-1)}\")\n",
    "\n",
    "#         optimizer.zero_grad()  # Reset gradients to zero\n",
    "#         outputs = model(inputs)  # Forward pass through the model\n",
    "\n",
    "#         # Reshape outputs and targets to match dimensions for loss calculation\n",
    "#         outputs = outputs.view(outputs.size(0), -1)\n",
    "#         targets = targets.view(targets.size(0), -1)\n",
    "\n",
    "#         loss = criterion(outputs, targets)  # Compute the loss\n",
    "#         loss.backward()  # Backpropagate the loss\n",
    "#         optimizer.step()  # Update model parameters\n",
    "\n",
    "#         train_loss += loss.item()  # Accumulate batch loss\n",
    "#         train_loader_tqdm.set_postfix({'Batch Loss': loss.item()})  # Update progress bar with batch loss\n",
    "\n",
    "#     train_loss /= len(train_loader)  # Compute average training loss for the epoch\n",
    "#     train_losses.append(train_loss)  # Store training loss for plotting\n",
    "\n",
    "#     model.eval()  # Set the model to evaluation mode\n",
    "#     val_loss = 0  # Initialize validation loss for the epoch\n",
    "#     val_loader_tqdm = tqdm(val_loader, desc=\"Validation\", leave=True)  # Progress bar for validation\n",
    "\n",
    "#     with torch.no_grad():  # Disable gradient computation for validation\n",
    "#         for inputs, targets in val_loader_tqdm:\n",
    "#             # Move inputs and targets to the specified device (CPU or GPU)\n",
    "#             inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "#             # Check if the input size matches the expected size\n",
    "#             if inputs.size(-1) != expected_input_size:\n",
    "#                 raise ValueError(f\"Expected input size {expected_input_size}, but got {inputs.size(-1)}\")\n",
    "\n",
    "#             outputs = model(inputs)  # Forward pass through the model\n",
    "\n",
    "#             # Reshape outputs and targets to match dimensions for loss calculation\n",
    "#             outputs = outputs.view(outputs.size(0), -1)\n",
    "#             targets = targets.view(targets.size(0), -1)\n",
    "\n",
    "#             loss = criterion(outputs, targets)  # Compute the loss\n",
    "#             val_loss += loss.item()  # Accumulate batch loss\n",
    "#             val_loader_tqdm.set_postfix({'Batch Loss': loss.item()})  # Update progress bar with batch loss\n",
    "\n",
    "#     val_loss /= len(val_loader)  # Compute average validation loss for the epoch\n",
    "#     val_losses.append(val_loss)  # Store validation loss for plotting\n",
    "\n",
    "#     # Print training and validation loss for the epoch\n",
    "#     print(f'Epoch {epoch + 1}/{epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')\n",
    "\n",
    "# # Save the trained model's state dictionary\n",
    "# torch.save(model.state_dict(), f'LSTM_rel_vel_bs128_hs{hidden_size}_lr00001_10k_dampening_3_layers_ROTNORM.pth')\n",
    "\n",
    "# # Plot training and validation loss over epochs\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(range(1, epochs + 1), train_losses, label='Training Loss')  # Plot training loss\n",
    "# plt.plot(range(1, epochs + 1), val_losses, label='Validation Loss')  # Plot validation loss\n",
    "# print(train_losses)  # Print training losses for debugging\n",
    "# print(val_losses)  # Print validation losses for debugging\n",
    "# plt.xlabel('Epoch')  # Label for x-axis\n",
    "# plt.ylabel('Loss')  # Label for y-axis\n",
    "# plt.title('Training and Validation Loss')  # Title of the plot\n",
    "# plt.legend()  # Add legend to the plot\n",
    "# plt.grid(True)  # Add grid to the plot\n",
    "# plt.show()  # Display the plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7da0e0382150>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7da0b5b98cb0, raw_cell=\"# Define the sweep configuration\n",
      "sweep_config = {\n",
      "..\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244617461436f6e2d776f726b73746174696f6e227d/home/lukas-zeh/Documents/GNN_CableSimulation/biLSTM/bi_lstm_model.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "BrokenPipeError",
     "evalue": "[Errno 32] Broken pipe",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/wandb_init.py:570\u001b[0m, in \u001b[0;36m_WandbInit._resume_backend\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39minterface \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresuming backend\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m--> 570\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterface\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpublish_resume\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/interface/interface.py:779\u001b[0m, in \u001b[0;36mInterfaceBase.publish_resume\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpublish_resume\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    778\u001b[0m     resume \u001b[38;5;241m=\u001b[39m pb\u001b[38;5;241m.\u001b[39mResumeRequest()\n\u001b[0;32m--> 779\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish_resume\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresume\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/interface/interface_shared.py:301\u001b[0m, in \u001b[0;36mInterfaceShared._publish_resume\u001b[0;34m(self, resume)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_publish_resume\u001b[39m(\u001b[38;5;28mself\u001b[39m, resume: pb\u001b[38;5;241m.\u001b[39mResumeRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    300\u001b[0m     rec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(resume\u001b[38;5;241m=\u001b[39mresume)\n\u001b[0;32m--> 301\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrec\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/interface/interface_sock.py:46\u001b[0m, in \u001b[0;36mInterfaceSock._publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_publish\u001b[39m(\u001b[38;5;28mself\u001b[39m, record: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpb.Record\u001b[39m\u001b[38;5;124m\"\u001b[39m, local: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign(record)\n\u001b[0;32m---> 46\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_record_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/lib/sock_client.py:224\u001b[0m, in \u001b[0;36mSockClient.send_record_publish\u001b[0;34m(self, record)\u001b[0m\n\u001b[1;32m    222\u001b[0m server_req\u001b[38;5;241m.\u001b[39mrequest_id \u001b[38;5;241m=\u001b[39m record\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mmailbox_slot\n\u001b[1;32m    223\u001b[0m server_req\u001b[38;5;241m.\u001b[39mrecord_publish\u001b[38;5;241m.\u001b[39mCopyFrom(record)\n\u001b[0;32m--> 224\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_server_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserver_req\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/lib/sock_client.py:154\u001b[0m, in \u001b[0;36mSockClient.send_server_request\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msend_server_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, msg: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 154\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/lib/sock_client.py:151\u001b[0m, in \u001b[0;36mSockClient._send_message\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    149\u001b[0m header \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39mpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<BI\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m\"\u001b[39m), raw_size)\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m--> 151\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sendall_with_error_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/lib/sock_client.py:130\u001b[0m, in \u001b[0;36mSockClient._sendall_with_error_handle\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    128\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 130\u001b[0m     sent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;66;03m# sent equal to 0 indicates a closed socket\u001b[39;00m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sent \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: 2y7kz9oi\n",
      "Sweep URL: https://wandb.ai/lukas-zeh-university-of-stuttgart/biLSTM/sweeps/2y7kz9oi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 7ov2ti17 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0001\n",
      "Exception in thread Thread-13 (_run_job):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n",
      "    self._function()\n",
      "  File \"/tmp/ipykernel_60059/3339386355.py\", line 25, in train_sweep\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/wandb_init.py\", line 1485, in init\n",
      "    wandb._sentry.reraise(e)\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/analytics/sentry.py\", line 156, in reraise\n",
      "    raise exc.with_traceback(sys.exc_info()[2])\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/wandb_init.py\", line 1471, in init\n",
      "    return wi.init(run_settings, run_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/wandb_init.py\", line 779, in init\n",
      "    with telemetry.context() as tel:\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/lib/telemetry.py\", line 42, in __exit__\n",
      "    self._run._telemetry_callback(self._obj)\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/wandb_run.py\", line 749, in _telemetry_callback\n",
      "    self._telemetry_flush()\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/wandb_run.py\", line 762, in _telemetry_flush\n",
      "    self._backend.interface._publish_telemetry(self._telemetry_obj)\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/interface/interface_shared.py\", line 70, in _publish_telemetry\n",
      "    self._publish(rec)\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/interface/interface_sock.py\", line 46, in _publish\n",
      "    self._sock_client.send_record_publish(record)\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/lib/sock_client.py\", line 224, in send_record_publish\n",
      "    self.send_server_request(server_req)\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/lib/sock_client.py\", line 154, in send_server_request\n",
      "    self._send_message(msg)\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/lib/sock_client.py\", line 151, in _send_message\n",
      "    self._sendall_with_error_handle(header + data)\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n",
      "    sent = self._sock.send(data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/threading.py\", line 1073, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/usr/lib/python3.12/threading.py\", line 1010, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/agents/pyagent.py\", line 311, in _run_job\n",
      "    wandb.finish(exit_code=1)\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/wandb_run.py\", line 4132, in finish\n",
      "    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/wandb_run.py\", line 449, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/wandb_run.py\", line 391, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/wandb_run.py\", line 2106, in finish\n",
      "    return self._finish(exit_code)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/wandb_run.py\", line 2113, in _finish\n",
      "    with telemetry.context(run=self) as tel:\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/lib/telemetry.py\", line 42, in __exit__\n",
      "    self._run._telemetry_callback(self._obj)\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/wandb_run.py\", line 749, in _telemetry_callback\n",
      "    self._telemetry_flush()\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/wandb_run.py\", line 762, in _telemetry_flush\n",
      "    self._backend.interface._publish_telemetry(self._telemetry_obj)\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/interface/interface_shared.py\", line 70, in _publish_telemetry\n",
      "    self._publish(rec)\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/interface/interface_sock.py\", line 46, in _publish\n",
      "    self._sock_client.send_record_publish(record)\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/lib/sock_client.py\", line 224, in send_record_publish\n",
      "    self.send_server_request(server_req)\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/lib/sock_client.py\", line 154, in send_server_request\n",
      "    self._send_message(msg)\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/lib/sock_client.py\", line 151, in _send_message\n",
      "    self._sendall_with_error_handle(header + data)\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n",
      "    sent = self._sock.send(data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 3jt3hcvw with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 1e-06\n",
      "Exception in thread Thread-14 (_run_job):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n",
      "    self._function()\n",
      "  File \"/tmp/ipykernel_60059/3339386355.py\", line 25, in train_sweep\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/wandb_init.py\", line 1485, in init\n",
      "    wandb._sentry.reraise(e)\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/analytics/sentry.py\", line 156, in reraise\n",
      "    raise exc.with_traceback(sys.exc_info()[2])\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/wandb_init.py\", line 1471, in init\n",
      "    return wi.init(run_settings, run_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/wandb_init.py\", line 779, in init\n",
      "    with telemetry.context() as tel:\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/lib/telemetry.py\", line 42, in __exit__\n",
      "    self._run._telemetry_callback(self._obj)\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/wandb_run.py\", line 749, in _telemetry_callback\n",
      "    self._telemetry_flush()\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/wandb_run.py\", line 762, in _telemetry_flush\n",
      "    self._backend.interface._publish_telemetry(self._telemetry_obj)\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/interface/interface_shared.py\", line 70, in _publish_telemetry\n",
      "    self._publish(rec)\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/interface/interface_sock.py\", line 46, in _publish\n",
      "    self._sock_client.send_record_publish(record)\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/lib/sock_client.py\", line 224, in send_record_publish\n",
      "    self.send_server_request(server_req)\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/lib/sock_client.py\", line 154, in send_server_request\n",
      "    self._send_message(msg)\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/lib/sock_client.py\", line 151, in _send_message\n",
      "    self._sendall_with_error_handle(header + data)\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n",
      "    sent = self._sock.send(data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/threading.py\", line 1073, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/usr/lib/python3.12/threading.py\", line 1010, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/agents/pyagent.py\", line 311, in _run_job\n",
      "    wandb.finish(exit_code=1)\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/wandb_run.py\", line 4132, in finish\n",
      "    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/wandb_run.py\", line 449, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/wandb_run.py\", line 391, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/wandb_run.py\", line 2106, in finish\n",
      "    return self._finish(exit_code)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/wandb_run.py\", line 2113, in _finish\n",
      "    with telemetry.context(run=self) as tel:\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/lib/telemetry.py\", line 42, in __exit__\n",
      "    self._run._telemetry_callback(self._obj)\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/wandb_run.py\", line 749, in _telemetry_callback\n",
      "    self._telemetry_flush()\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/wandb_run.py\", line 762, in _telemetry_flush\n",
      "    self._backend.interface._publish_telemetry(self._telemetry_obj)\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/interface/interface_shared.py\", line 70, in _publish_telemetry\n",
      "    self._publish(rec)\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/interface/interface_sock.py\", line 46, in _publish\n",
      "    self._sock_client.send_record_publish(record)\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/lib/sock_client.py\", line 224, in send_record_publish\n",
      "    self.send_server_request(server_req)\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/lib/sock_client.py\", line 154, in send_server_request\n",
      "    self._send_message(msg)\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/lib/sock_client.py\", line 151, in _send_message\n",
      "    self._sendall_with_error_handle(header + data)\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n",
      "    sent = self._sock.send(data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: mjcvd057 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0001\n",
      "Exception in thread Thread-15 (_run_job):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n",
      "    self._function()\n",
      "  File \"/tmp/ipykernel_60059/3339386355.py\", line 25, in train_sweep\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/wandb_init.py\", line 1485, in init\n",
      "    wandb._sentry.reraise(e)\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/analytics/sentry.py\", line 156, in reraise\n",
      "    raise exc.with_traceback(sys.exc_info()[2])\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/wandb_init.py\", line 1471, in init\n",
      "    return wi.init(run_settings, run_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/wandb_init.py\", line 779, in init\n",
      "    with telemetry.context() as tel:\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/lib/telemetry.py\", line 42, in __exit__\n",
      "    self._run._telemetry_callback(self._obj)\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/wandb_run.py\", line 749, in _telemetry_callback\n",
      "    self._telemetry_flush()\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/wandb_run.py\", line 762, in _telemetry_flush\n",
      "    self._backend.interface._publish_telemetry(self._telemetry_obj)\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/interface/interface_shared.py\", line 70, in _publish_telemetry\n",
      "    self._publish(rec)\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/interface/interface_sock.py\", line 46, in _publish\n",
      "    self._sock_client.send_record_publish(record)\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/lib/sock_client.py\", line 224, in send_record_publish\n",
      "    self.send_server_request(server_req)\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/lib/sock_client.py\", line 154, in send_server_request\n",
      "    self._send_message(msg)\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/lib/sock_client.py\", line 151, in _send_message\n",
      "    self._sendall_with_error_handle(header + data)\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n",
      "    sent = self._sock.send(data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/threading.py\", line 1073, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/usr/lib/python3.12/threading.py\", line 1010, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/agents/pyagent.py\", line 311, in _run_job\n",
      "    wandb.finish(exit_code=1)\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/wandb_run.py\", line 4132, in finish\n",
      "    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/wandb_run.py\", line 449, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/wandb_run.py\", line 391, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/wandb_run.py\", line 2106, in finish\n",
      "    return self._finish(exit_code)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/wandb_run.py\", line 2113, in _finish\n",
      "    with telemetry.context(run=self) as tel:\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/lib/telemetry.py\", line 42, in __exit__\n",
      "    self._run._telemetry_callback(self._obj)\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/wandb_run.py\", line 749, in _telemetry_callback\n",
      "    self._telemetry_flush()\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/wandb_run.py\", line 762, in _telemetry_flush\n",
      "    self._backend.interface._publish_telemetry(self._telemetry_obj)\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/interface/interface_shared.py\", line 70, in _publish_telemetry\n",
      "    self._publish(rec)\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/interface/interface_sock.py\", line 46, in _publish\n",
      "    self._sock_client.send_record_publish(record)\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/lib/sock_client.py\", line 224, in send_record_publish\n",
      "    self.send_server_request(server_req)\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/lib/sock_client.py\", line 154, in send_server_request\n",
      "    self._send_message(msg)\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/lib/sock_client.py\", line 151, in _send_message\n",
      "    self._sendall_with_error_handle(header + data)\n",
      "  File \"/home/lukas-zeh/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n",
      "    sent = self._sock.send(data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7da0e0382150>> (for post_run_cell), with arguments args (<ExecutionResult object at 7da0b5b98410, execution_count=12 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7da0b5b98cb0, raw_cell=\"# Define the sweep configuration\n",
      "sweep_config = {\n",
      "..\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244617461436f6e2d776f726b73746174696f6e227d/home/lukas-zeh/Documents/GNN_CableSimulation/biLSTM/bi_lstm_model.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D> result=None>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "BrokenPipeError",
     "evalue": "[Errno 32] Broken pipe",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/wandb_init.py:565\u001b[0m, in \u001b[0;36m_WandbInit._pause_backend\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    563\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39minterface \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    564\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpausing backend\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m--> 565\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterface\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpublish_pause\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/interface/interface.py:771\u001b[0m, in \u001b[0;36mInterfaceBase.publish_pause\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    769\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpublish_pause\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    770\u001b[0m     pause \u001b[38;5;241m=\u001b[39m pb\u001b[38;5;241m.\u001b[39mPauseRequest()\n\u001b[0;32m--> 771\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish_pause\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpause\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/interface/interface_shared.py:297\u001b[0m, in \u001b[0;36mInterfaceShared._publish_pause\u001b[0;34m(self, pause)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_publish_pause\u001b[39m(\u001b[38;5;28mself\u001b[39m, pause: pb\u001b[38;5;241m.\u001b[39mPauseRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    296\u001b[0m     rec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(pause\u001b[38;5;241m=\u001b[39mpause)\n\u001b[0;32m--> 297\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrec\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/interface/interface_sock.py:46\u001b[0m, in \u001b[0;36mInterfaceSock._publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_publish\u001b[39m(\u001b[38;5;28mself\u001b[39m, record: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpb.Record\u001b[39m\u001b[38;5;124m\"\u001b[39m, local: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign(record)\n\u001b[0;32m---> 46\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_record_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/lib/sock_client.py:224\u001b[0m, in \u001b[0;36mSockClient.send_record_publish\u001b[0;34m(self, record)\u001b[0m\n\u001b[1;32m    222\u001b[0m server_req\u001b[38;5;241m.\u001b[39mrequest_id \u001b[38;5;241m=\u001b[39m record\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mmailbox_slot\n\u001b[1;32m    223\u001b[0m server_req\u001b[38;5;241m.\u001b[39mrecord_publish\u001b[38;5;241m.\u001b[39mCopyFrom(record)\n\u001b[0;32m--> 224\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_server_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserver_req\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/lib/sock_client.py:154\u001b[0m, in \u001b[0;36mSockClient.send_server_request\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msend_server_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, msg: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 154\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/lib/sock_client.py:151\u001b[0m, in \u001b[0;36mSockClient._send_message\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    149\u001b[0m header \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39mpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<BI\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m\"\u001b[39m), raw_size)\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m--> 151\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sendall_with_error_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/wandb/sdk/lib/sock_client.py:130\u001b[0m, in \u001b[0;36mSockClient._sendall_with_error_handle\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    128\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 130\u001b[0m     sent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;66;03m# sent equal to 0 indicates a closed socket\u001b[39;00m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sent \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"
     ]
    }
   ],
   "source": [
    "# Define the sweep configuration\n",
    "sweep_config = {\n",
    "    \"method\": \"random\",  # Random search\n",
    "    \"metric\": {\n",
    "        \"name\": \"val_loss\",  # Metric to optimize\n",
    "        \"goal\": \"minimize\"   # Minimize the validation loss\n",
    "    },\n",
    "    \"parameters\": {\n",
    "        \"hidden_size\": {\"values\": [32, 64, 128, 256]}, #,\n",
    "        \"num_layers\": {\"values\": [1, 2, 3, 4, 5, 6]},\n",
    "        \"learning_rate\": {\"values\": [1e-3, 1e-4, 1e-5, 1e-6]},\n",
    "        \"weight_decay\": {\"values\": [1e-4, 1e-5, 1e-6, 1e-7]},\n",
    "        \"batch_size\": {\"values\": [512]}, # 8, 16, 32, 64, 128, 256, \n",
    "        \"epochs\": {\"values\": [1]}, #10, 20, 30, 40, 50\n",
    "    }\n",
    "}\n",
    "\n",
    "# Initialize the sweep\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"biLSTM\", entity=\"lukas-zeh-university-of-stuttgart\")\n",
    "global id\n",
    "id = 0\n",
    "\n",
    "# Define the training function for the sweep\n",
    "def train_sweep():\n",
    "    # Initialize a new wandb run\n",
    "    run = wandb.init()\n",
    "\n",
    "    # Access the hyperparameters from the sweep configuration\n",
    "    config = wandb.config\n",
    "\n",
    "    # Initialize the model, optimizer, and criterion\n",
    "    model = MultiMarkerLSTM(hidden_size=config.hidden_size, num_layers=config.num_layers)\n",
    "    model = model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config.learning_rate, weight_decay=config.weight_decay)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # Update DataLoader with the batch size from the sweep configuration\n",
    "    train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=config.batch_size, shuffle=False)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(config.epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        train_loss /= len(train_loader)\n",
    "\n",
    "        # Validation loop\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                val_loss += loss.item()\n",
    "        val_loss /= len(val_loader)\n",
    "\n",
    "        # Log metrics to wandb\n",
    "        wandb.log({\"epoch\": epoch + 1, \"train_loss\": train_loss, \"val_loss\": val_loss})\n",
    "\n",
    "    # Finish the wandb run\n",
    "    run.finish()\n",
    "\n",
    "    # Save the model after each try\n",
    "    model_path = f\"model_try_{id + 1}_hidden_{config.hidden_size}_layers_{config.num_layers}.pth\"\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    id += 1\n",
    "    print(f\"Model saved to {model_path}\")\n",
    "\n",
    "# Start the sweep agent\n",
    "wandb.agent(sweep_id, function=train_sweep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiMarkerLSTM(\n",
       "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
       "  (lstm): LSTM(12, 256, num_layers=3, batch_first=True, bidirectional=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the device to CPU\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# Load the pre-trained model's state dictionary from the specified file\n",
    "# The `map_location=device` ensures the model is loaded onto the CPU\n",
    "model.load_state_dict(torch.load(\"models/BEST_bi_LSTM_2_rel_vel_bs128_hs256_lr00001_nl3_epochs50_10k.pth\", weights_only=True, map_location=device))\n",
    "\n",
    "# Move the model to the specified device (CPU in this case)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def velocity_error(groundtruth_vel, predicted_vel):\n",
    "    \"\"\"\n",
    "    Calculates the relative velocity error e_vel in percentage.\n",
    "\n",
    "    Parameters:\n",
    "    - groundtruth_vel: numpy array, the true velocity (e.g., [N, D])\n",
    "    - predicted_vel: numpy array, the predicted velocity (e.g., [N, D])\n",
    "\n",
    "    Returns:\n",
    "    - e_vel: float, the relative error in percentage\n",
    "    \"\"\"\n",
    "    # Calculate the L2 norm of the difference between groundtruth and prediction\n",
    "    numerator = torch.norm(groundtruth_vel - predicted_vel, dim=1)\n",
    "\n",
    "    # Calculate the L2 norm of the groundtruth velocity\n",
    "    denominator = torch.norm(groundtruth_vel, dim=1)\n",
    "\n",
    "    # Calculate the relative error\n",
    "    e_vel = (numerator / denominator) * 100  # Convert to percentage\n",
    "\n",
    "    return e_vel\n",
    "\n",
    "# Example: EE position in 2D\n",
    "def reconstruct_absolute_positions(rel_positions, ref_pos):\n",
    "    \"\"\"\n",
    "    Reconstructs the absolute position from the relative positions (or displacements).\n",
    "    We assume that the first entry is the relative offset to the reference,\n",
    "    and the following entries are differences relative to the previous marker.\n",
    "\n",
    "    rel_positions: Tensor with shape (num_markers, 2)\n",
    "    ref_pos: Tensor with shape (2,)\n",
    "\n",
    "    Returns: Tensor with shape (num_markers, 2)\n",
    "    \"\"\"\n",
    "    abs_pos = []\n",
    "    cum_pos = ref_pos.clone()\n",
    "    for i, rel in enumerate(rel_positions):\n",
    "        # For the first marker we assume: abs_pos[0] = ref_pos + rel[0]\n",
    "        # For i > 0: add the difference\n",
    "        print(\"Cumulative Position\", cum_pos)\n",
    "        print(\"Relative Position\", rel)\n",
    "        cum_pos = cum_pos + rel\n",
    "        abs_pos.append(cum_pos.clone())\n",
    "    return torch.stack(abs_pos, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EE_pos normalized Shape torch.Size([250, 4])\n",
      "EE_vel normalized Shape torch.Size([250, 4])\n",
      "cable_pos normalized Shape torch.Size([250, 9, 2])\n"
     ]
    }
   ],
   "source": [
    "file_path = '/home/lukas-zeh/Documents/GNN_CableSimulation/simulationData/rollout_MPPI/simulation_data_01.npz'\n",
    "dataset = SimulationDataset(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Error in m: No data available\n",
      "Min Error in m: No data available\n",
      "Mean Velocity Error in %: No data available\n",
      "Mean Shape Error in m: No data available\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Define the range and step size for indices to evaluate\n",
    "start_idx = 50\n",
    "step = 250\n",
    "end_idx = len(dataset) - 250\n",
    "\n",
    "# Initialize lists to store errors\n",
    "velocity_error_list = []  # List to store velocity errors\n",
    "shape_error_list = []  # List to store shape errors\n",
    "max_error_list = []  # List to store maximum errors\n",
    "min_error_list = []  # List to store minimum errors\n",
    "\n",
    "# Loop through the dataset at specified intervals\n",
    "for idx in range(start_idx, end_idx, step):\n",
    "        # Get the input and target data for the current index\n",
    "        inputs, targets = dataset[idx]\n",
    "\n",
    "        # Move inputs and targets to the specified device (CPU or GPU)\n",
    "        inputs = inputs.to(device).unsqueeze(0)  # Add batch dimension: (1, num_markers, features)\n",
    "        targets = targets.to(device).float()  # Convert targets to float: (num_markers, 2)\n",
    "\n",
    "        with torch.no_grad():  # Disable gradient computation for evaluation\n",
    "                outputs = model(inputs)  # Forward pass through the model\n",
    "                predictions = outputs.squeeze(0)  # Remove batch dimension: (num_markers, 2)\n",
    "\n",
    "        # Get the normalized end-effector (EE) position\n",
    "        EE_pos_x, EE_pos_y = dataset.EE_pos_normalized[idx, :2]\n",
    "        basis_position = torch.tensor([EE_pos_x, EE_pos_y], device=device)\n",
    "\n",
    "        # Define mean and standard deviation for velocity normalization\n",
    "        cable_vel_mean = torch.tensor([-7.6191895e-08,  5.4330588e-08]).to(device)\n",
    "        cable_vel_std = torch.tensor([0.007593654096126556, 0.006266195327043533]).to(device)\n",
    "\n",
    "        # Denormalize predictions and targets\n",
    "        prediction_entnorm = predictions * cable_vel_std + cable_vel_mean\n",
    "        target_entnorm = targets * cable_vel_std + cable_vel_mean\n",
    "\n",
    "        # Calculate velocity error and append to the list\n",
    "        velocity_error_prediction = velocity_error(target_entnorm, prediction_entnorm)\n",
    "        velocity_error_list.append(velocity_error_prediction)\n",
    "\n",
    "        # Calculate absolute positions for predictions and targets\n",
    "        pred_abs = dataset.get_absolute_coords(idx).view(9, 2) + prediction_entnorm\n",
    "        target_abs = dataset.get_absolute_coords(idx).view(9, 2) + target_entnorm\n",
    "\n",
    "        # Calculate shape error and append to the list\n",
    "        e_shape = torch.norm(pred_abs - target_abs, p=2)\n",
    "        shape_error_list.append(e_shape)\n",
    "\n",
    "        # Calculate maximum and minimum errors and append to their respective lists\n",
    "        max_error = (pred_abs - target_abs).norm(dim=1).max()\n",
    "        min_error = (pred_abs - target_abs).norm(dim=1).min()\n",
    "        max_error_list.append(max_error)\n",
    "        min_error_list.append(min_error)\n",
    "\n",
    "        # Get the absolute EE position\n",
    "        EE_pos_x, EE_pos_y = dataset.EE_pos[idx, :2]\n",
    "        basis_position = torch.tensor([EE_pos_x, EE_pos_y], device=device)\n",
    "        basis_position = basis_position.view(1, 2)\n",
    "\n",
    "# Calculate and print the maximum error if the list is not empty\n",
    "if max_error_list:\n",
    "    max_error_mean = np.max(max_error_list)\n",
    "    print('Max Error in m: ', max_error_mean)\n",
    "else:\n",
    "    print('Max Error in m: No data available')\n",
    "\n",
    "# Calculate and print the minimum error if the list is not empty\n",
    "if min_error_list:\n",
    "    min_error_mean = np.min(min_error_list)\n",
    "    print('Min Error in m: ', min_error_mean)\n",
    "else:\n",
    "    print('Min Error in m: No data available')\n",
    "\n",
    "# Calculate and print the mean velocity error if the list is not empty\n",
    "if velocity_error_list:\n",
    "    vel_error_mean = np.mean(velocity_error_list)\n",
    "    print(f\"Mean Velocity Error in %: {vel_error_mean}\")\n",
    "else:\n",
    "    print('Mean Velocity Error in %: No data available')\n",
    "\n",
    "# Calculate and print the mean shape error if the list is not empty\n",
    "if shape_error_list:\n",
    "    shape_error_mean = np.mean(shape_error_list)\n",
    "    print(f\"Mean Shape Error in m: {shape_error_mean}\")\n",
    "else:\n",
    "    print('Mean Shape Error in m: No data available')\n",
    "\n",
    "# Plot the predicted and actual cable shapes\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "\n",
    "# Plot predicted absolute shape\n",
    "ax.plot(pred_abs[:, 0].cpu().numpy(), pred_abs[:, 1].cpu().numpy(),\n",
    "                color='red', alpha=0.6, marker='o', label='Predicted Absolute Shape')\n",
    "\n",
    "# Plot actual absolute shape\n",
    "ax.plot(target_abs[:, 0].cpu().numpy(), target_abs[:, 1].cpu().numpy(),\n",
    "                color='blue', alpha=0.6, marker='o', label='Actual Absolute Shape')\n",
    "\n",
    "# Plot end-effector position\n",
    "ax.plot(basis_position[:, 0].cpu().numpy(), basis_position[:, 1].cpu().numpy(),\n",
    "                color='green', alpha=0.6, marker='o', label='EE')\n",
    "\n",
    "# Set plot labels and title\n",
    "ax.set_xlabel('X Position')\n",
    "ax.set_ylabel('Y Position')\n",
    "ax.set_title('Predicted vs Actual Cable Shape (Absolute 2D Positions)')\n",
    "\n",
    "# Add legend and grid\n",
    "ax.legend()\n",
    "ax.grid(True)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'EE_pos is not a file in the archive'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      4\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/lukas-zeh/Documents/GNN_CableSimulation/simulationData/simulation_data_rollout.npz\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 5\u001b[0m rollout_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mSimulationDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 7\u001b[0m, in \u001b[0;36mSimulationDataset.__init__\u001b[0;34m(self, file_path)\u001b[0m\n\u001b[1;32m      4\u001b[0m data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(file_path)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Extract and preprocess end-effector (EE) position and velocity\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mEE_pos \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mEE_pos\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m[:, [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m4\u001b[39m]], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)  \u001b[38;5;66;03m# Shape: (_, 4)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mEE_vel \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEE_vel\u001b[39m\u001b[38;5;124m'\u001b[39m][:, [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m5\u001b[39m]], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.02\u001b[39m  \u001b[38;5;66;03m# Shape: (_, 4)\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Extract cable positions and initialize noisy version\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GNN_CableSimulation/.venv/lib/python3.12/site-packages/numpy/lib/_npyio_impl.py:261\u001b[0m, in \u001b[0;36mNpzFile.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mzip\u001b[38;5;241m.\u001b[39mread(key)\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 261\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a file in the archive\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'EE_pos is not a file in the archive'"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "model.load_state_dict(torch.load(\"models/BEST_bi_LSTM_2_rel_vel_bs128_hs256_lr00001_nl3_epochs50_10k.pth\", weights_only=True, map_location=device)) #\n",
    "model.to(device)\n",
    "file_path = '/home/lukas-zeh/Documents/GNN_CableSimulation/simulationData/simulation_data_rollout.npz'\n",
    "rollout_dataset = SimulationDataset(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rollout_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 105\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m trajectories, ground_truth_list, EE_Pos_list, velocity_error_list, shape_error_list\n\u001b[1;32m    104\u001b[0m \u001b[38;5;66;03m# Perform a rollout with the model and dataset\u001b[39;00m\n\u001b[0;32m--> 105\u001b[0m traj, gr_true, EE_list, velocity_error_list, shape_error_list \u001b[38;5;241m=\u001b[39m rollout_velocity(model, dataset\u001b[38;5;241m=\u001b[39m\u001b[43mrollout_dataset\u001b[49m, rollout_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m)\n\u001b[1;32m    107\u001b[0m \u001b[38;5;66;03m# Print velocity and shape errors\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvelocity_error_list\u001b[39m\u001b[38;5;124m\"\u001b[39m, velocity_error_list)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rollout_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "# Function to calculate relative positions of markers with respect to the end-effector (EE)\n",
    "def get_local_relativ_positions(idx, coords, normalize=False):\n",
    "    relative_DLO = coords\n",
    "\n",
    "    # Get the position of the end-effector (EE) for the given index\n",
    "    EE_pos = dataset.EE_pos[idx, :2]\n",
    "    # Calculate relative positions of markers with respect to the EE\n",
    "    rel_positions = coords - EE_pos.unsqueeze(0)  # (9, 2)\n",
    "\n",
    "    if normalize:\n",
    "        # Normalize the relative positions using L2 norm\n",
    "        l2_norm = torch.norm(rel_positions, dim=1, keepdim=True)\n",
    "        l2_norm[l2_norm == 0] = 1e-9  # Avoid division by zero\n",
    "        rel_positions = rel_positions / l2_norm\n",
    "\n",
    "    return rel_positions\n",
    "\n",
    "# Function to perform a rollout of the model for a given number of steps\n",
    "def rollout_velocity(model, dataset, rollout_steps=10):\n",
    "    max_idx = len(dataset) - 1 - rollout_steps\n",
    "    # Randomly select an index for the rollout\n",
    "    random_idx = random.randint(0, max_idx)\n",
    "    inputs, targets = dataset[random_idx]\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    # Get the initial positions of the cable markers\n",
    "    coords = dataset.cable_pos[random_idx, :, :2]\n",
    "    coords = coords[6:-3]  # Select a subset of markers\n",
    "    new_abs_position = coords[::5]  # Downsample the markers\n",
    "    traj = new_abs_position  # Initialize trajectory\n",
    "    trajectories = []  # List to store predicted trajectories\n",
    "    ground_truth_list = []  # List to store ground truth trajectories\n",
    "    EE_Pos_list = []  # List to store EE positions\n",
    "    velocity_error_list = []  # List to store velocity errors\n",
    "    shape_error_list = []  # List to store shape errors\n",
    "\n",
    "    # Mean and standard deviation for velocity normalization\n",
    "    cable_vel_mean = np.array([-7.6191895e-08,  5.4330588e-08])\n",
    "    cable_vel_std  = np.array([0.007593654096126556, 0.006266195327043533])\n",
    "\n",
    "    for step in range(rollout_steps):\n",
    "        with torch.no_grad():  # Disable gradient computation for inference\n",
    "            # Get the normalized robot state (position and velocity)\n",
    "            current_robot_state_pos = dataset.EE_pos_normalized[random_idx + step].unsqueeze(0).repeat(dataset.num_markers, 1)  # (num_markers, 4)\n",
    "            current_robot_state_vel = dataset.EE_vel_normalized[random_idx + step].unsqueeze(0).repeat(dataset.num_markers, 1)  # (num_markers, 4)\n",
    "            current_robot_state = torch.cat((current_robot_state_pos, current_robot_state_vel), dim=1)  # (num_markers, 8)\n",
    "\n",
    "            if step == 0:\n",
    "                # Get normalized relative positions for the first step\n",
    "                normalized_relative_DLO = get_local_relativ_positions(idx=random_idx + step, coords=new_abs_position, normalize=True)\n",
    "                velocity_prediction = dataset.get_norm_marker_velocity(random_idx)\n",
    "            else:\n",
    "                # Calculate normalized relative positions for subsequent steps\n",
    "                EE_pos = dataset.EE_pos[random_idx + step, :2]\n",
    "                current_relative_dlo_state = new_abs_position - EE_pos\n",
    "                norms = torch.norm(current_relative_dlo_state, dim=1, keepdim=True)  # => shape (8, 1)\n",
    "                normalized_relative_DLO = current_relative_dlo_state / (norms + 1e-9)\n",
    "\n",
    "            # Combine relative positions and velocity predictions\n",
    "            current_dlo_velocity = velocity_prediction\n",
    "            current_relative_dlo_state = torch.cat((normalized_relative_DLO, current_dlo_velocity), dim=1)\n",
    "            # Combine robot state and DLO state as input to the model\n",
    "            inputs = torch.cat((current_robot_state, current_relative_dlo_state), dim=1)\n",
    "            inputs = inputs.float()\n",
    "\n",
    "            # Predict the velocity using the model\n",
    "            velocity_prediction = model(inputs)\n",
    "            # Denormalize the predicted velocity\n",
    "            new_velocity = (velocity_prediction * cable_vel_std) + (cable_vel_mean + 1e-9)\n",
    "\n",
    "            if step == 0:\n",
    "                # Get the absolute positions for the first step\n",
    "                new_abs_position = dataset.get_absolute_coords(random_idx + step).view(9, 2)\n",
    "            else:\n",
    "                # Update the absolute positions using the predicted velocity\n",
    "                new_abs_position = new_abs_position + new_velocity\n",
    "\n",
    "            # Get the ground truth for the current step\n",
    "            inputs_dummy, ground_truth = dataset[random_idx + step]\n",
    "            ground_truth_entnorm = (targets * cable_vel_std) + (cable_vel_mean + 1e-9)\n",
    "            ground_truth = dataset.get_absolute_coords(random_idx + step).view(9, 2) + ground_truth_entnorm\n",
    "\n",
    "            # Store the EE position\n",
    "            EE_pos_x, EE_pos_y = dataset.EE_pos[random_idx + step, :2]\n",
    "            basis_position = torch.tensor([EE_pos_x, EE_pos_y], device=device)\n",
    "            basis_position = basis_position.view(1, 2)\n",
    "            EE_Pos_list.append(basis_position.numpy())\n",
    "\n",
    "            # Append ground truth and predicted trajectory\n",
    "            ground_truth_list.append(ground_truth.numpy())\n",
    "            trajectories.append(new_abs_position.numpy())\n",
    "\n",
    "            # Calculate velocity error and shape error\n",
    "            velocity_error_prediction = velocity_error(ground_truth_entnorm, new_velocity.view(9, 2))\n",
    "            velocity_error_list.append(velocity_error_prediction)\n",
    "            e_shape = torch.norm(new_abs_position - ground_truth, p=2)\n",
    "            shape_error_list.append(e_shape)\n",
    "\n",
    "            # Update the trajectory\n",
    "            traj = torch.cat((traj, new_abs_position), dim=1)\n",
    "\n",
    "    return trajectories, ground_truth_list, EE_Pos_list, velocity_error_list, shape_error_list\n",
    "\n",
    "# Perform a rollout with the model and dataset\n",
    "traj, gr_true, EE_list, velocity_error_list, shape_error_list = rollout_velocity(model, dataset=rollout_dataset, rollout_steps=50)\n",
    "\n",
    "# Print velocity and shape errors\n",
    "print(\"velocity_error_list\", velocity_error_list)\n",
    "print(\"shape_error_list\", shape_error_list)\n",
    "\n",
    "# Convert trajectories, ground truth, and EE positions to numpy arrays\n",
    "traj = np.array(traj)\n",
    "gr_true = np.array(gr_true)\n",
    "ee_pos = np.array(EE_list)\n",
    "\n",
    "# Plot the trajectories and ground truth\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i in range(0, len(traj), 49):  # Plot every 49th trajectory\n",
    "    trajectory = traj[i]\n",
    "    ground_truth = gr_true[i]\n",
    "    ee_position = ee_pos[i]\n",
    "\n",
    "    # Extract x and y coordinates\n",
    "    x, y = trajectory[:, 0], trajectory[:, 1]\n",
    "    x_g, y_g = ground_truth[:, 0], ground_truth[:, 1]\n",
    "    x_e, y_e = ee_position[:, 0], ee_position[:, 1]\n",
    "\n",
    "    # Plot predicted trajectory and ground truth\n",
    "    plt.plot(x, y, marker='o', color='b', linestyle='-', linewidth=6)\n",
    "    plt.plot(x_g, y_g, marker='o', color='r', linestyle='-', linewidth=6, alpha=0.4)\n",
    "\n",
    "# Add labels and grid to the plot\n",
    "plt.xlabel('X-Coordinate', fontsize=14)\n",
    "plt.ylabel('Y-Coordinate', fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'traj' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Get the last index of the trajectory\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[43mtraj\u001b[49m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# Last index of 'traj'\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Extract the trajectory, ground truth, and end-effector position for the last step\u001b[39;00m\n\u001b[1;32m      5\u001b[0m trajectory \u001b[38;5;241m=\u001b[39m traj[i]  \u001b[38;5;66;03m# Predicted trajectory at the last step\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'traj' is not defined"
     ]
    }
   ],
   "source": [
    "# Get the last index of the trajectory\n",
    "i = len(traj) - 1  # Last index of 'traj'\n",
    "\n",
    "# Extract the trajectory, ground truth, and end-effector position for the last step\n",
    "trajectory = traj[i]  # Predicted trajectory at the last step\n",
    "ground_truth = gr_true[i]  # Ground truth trajectory at the last step\n",
    "ee_position = ee_pos[i]  # End-effector position at the last step\n",
    "\n",
    "# Extract x and y coordinates for the predicted trajectory\n",
    "x, y = trajectory[:, 0], trajectory[:, 1]\n",
    "\n",
    "# Extract x and y coordinates for the ground truth trajectory\n",
    "x_g, y_g = ground_truth[:, 0], ground_truth[:, 1]\n",
    "\n",
    "# Extract x and y coordinates for the end-effector position\n",
    "x_e, y_e = ee_position[:, 0], ee_position[:, 1]\n",
    "\n",
    "# Create a plot to visualize the predicted and ground truth trajectories\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Plot the predicted trajectory\n",
    "plt.plot(x, y, marker='o', color='b', linestyle='-', linewidth=6, label='Predicted Trajectory')\n",
    "\n",
    "# Plot the ground truth trajectory\n",
    "plt.plot(x_g, y_g, marker='o', color='r', linestyle='-', linewidth=6, alpha=0.4, label='Ground Truth Trajectory')\n",
    "\n",
    "# Add labels and grid to the plot\n",
    "plt.xlabel('X-Coordinate', fontsize=14)  # Label for x-axis\n",
    "plt.ylabel('Y-Coordinate', fontsize=14)  # Label for y-axis\n",
    "plt.grid(True)  # Add grid to the plot\n",
    "\n",
    "# Add a legend to differentiate between predicted and ground truth trajectories\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'traj' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 103\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m HTML(ani\u001b[38;5;241m.\u001b[39mto_html5_video())  \u001b[38;5;66;03m# Return the animation as an HTML video\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;66;03m# Create the animation and display it\u001b[39;00m\n\u001b[0;32m--> 103\u001b[0m animation \u001b[38;5;241m=\u001b[39m create_animation(\u001b[43mtraj\u001b[49m, gr_true, ee_pos)\n\u001b[1;32m    104\u001b[0m animation\n",
      "\u001b[0;31mNameError\u001b[0m: name 'traj' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import numpy as np\n",
    "from IPython.display import HTML\n",
    "\n",
    "def create_animation(traj, gr_true, ee_pos):\n",
    "    \"\"\"\n",
    "    Creates an animation to visualize the predicted trajectory, ground truth, and end-effector position.\n",
    "\n",
    "    Parameters:\n",
    "    - traj: Predicted trajectory (3D array of shape [Steps, Markers, Coordinates])\n",
    "    - gr_true: Ground truth trajectory (3D array of shape [Steps, Markers, Coordinates])\n",
    "    - ee_pos: End-effector positions (2D array of shape [Steps, Coordinates])\n",
    "\n",
    "    Returns:\n",
    "    - HTML object containing the animation.\n",
    "    \"\"\"\n",
    "    # Ensure the end-effector position has the correct shape\n",
    "    ee_pos = ee_pos.squeeze(1)\n",
    "\n",
    "    # Debugging: Print shapes of input arrays\n",
    "    print(\"Shape of traj:\", traj.shape)\n",
    "    print(\"Shape of gr_true:\", gr_true.shape)\n",
    "    print(\"Shape of ee_pos:\", ee_pos.shape)\n",
    "\n",
    "    # Assertions to ensure input dimensions are correct\n",
    "    assert traj.ndim == 3, \"traj should be 3D: (Steps, Markers, Coordinates)\"\n",
    "    assert gr_true.ndim == 3, \"gr_true should be 3D: (Steps, Markers, Coordinates)\"\n",
    "    assert ee_pos.ndim == 2, \"ee_pos should be 2D: (Steps, Coordinates)\"\n",
    "\n",
    "    # Flatten all data to calculate global min and max for x and y axes\n",
    "    all_pred = traj.reshape(-1, 2)  # Flatten predicted trajectory\n",
    "    all_true = gr_true.reshape(-1, 2)  # Flatten ground truth trajectory\n",
    "    all_ee = ee_pos  # End-effector positions\n",
    "\n",
    "    # Calculate axis limits with some padding\n",
    "    min_x = min(np.min(all_pred[:, 0]), np.min(all_true[:, 0]), np.min(all_ee[:, 0])) - 0.1\n",
    "    max_x = max(np.max(all_pred[:, 0]), np.max(all_true[:, 0]), np.max(all_ee[:, 0])) + 0.1\n",
    "    min_y = min(np.min(all_pred[:, 1]), np.min(all_true[:, 1]), np.min(all_ee[:, 1])) - 0.1\n",
    "    max_y = max(np.max(all_pred[:, 1]), np.max(all_true[:, 1]), np.max(all_ee[:, 1])) + 0.1\n",
    "\n",
    "    # Create a figure and axis for the animation\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax.set_xlim(min_x, max_x)  # Set x-axis limits\n",
    "    ax.set_ylim(min_y, max_y)  # Set y-axis limits\n",
    "    ax.set_title('Trajektorien Animation')  # Title of the plot\n",
    "    ax.set_xlabel('X-Koordinate')  # Label for x-axis\n",
    "    ax.set_ylabel('Y-Koordinate')  # Label for y-axis\n",
    "    ax.grid(True)  # Add grid to the plot\n",
    "\n",
    "    # Initialize plot elements for predicted trajectory, ground truth, and end-effector\n",
    "    pred_line, = ax.plot([], [], 'bo-', ms=4, alpha=1, linewidth=2, label='Vorhersage')  # Predicted trajectory\n",
    "    true_line, = ax.plot([], [], 'ro-', ms=4, alpha=0.5, linewidth=2, label='Ground Truth')  # Ground truth trajectory\n",
    "    ee_line, = ax.plot([], [], 'rx', ms=8, label='Endeffektor')  # End-effector position\n",
    "    ax.legend()  # Add legend to the plot\n",
    "\n",
    "    def init():\n",
    "        \"\"\"\n",
    "        Initialization function for the animation.\n",
    "        Clears the data for all plot elements.\n",
    "        \"\"\"\n",
    "        pred_line.set_data([], [])\n",
    "        true_line.set_data([], [])\n",
    "        ee_line.set_data([], [])\n",
    "        return pred_line, true_line, ee_line\n",
    "\n",
    "    def update(frame):\n",
    "        \"\"\"\n",
    "        Update function for each frame of the animation.\n",
    "\n",
    "        Parameters:\n",
    "        - frame: Current frame index.\n",
    "\n",
    "        Updates the data for predicted trajectory, ground truth, and end-effector position.\n",
    "        \"\"\"\n",
    "        # Get the data for the current frame\n",
    "        current_pred = traj[frame]  # Predicted trajectory for the current frame\n",
    "        current_true = gr_true[frame]  # Ground truth trajectory for the current frame\n",
    "        current_ee = ee_pos[frame]  # End-effector position for the current frame\n",
    "\n",
    "        # Update the plot elements with the current data\n",
    "        pred_line.set_data(current_pred[:, 0], current_pred[:, 1])  # Update predicted trajectory\n",
    "        true_line.set_data(current_true[:, 0], current_true[:, 1])  # Update ground truth trajectory\n",
    "        ee_line.set_data([current_ee[0]], [current_ee[1]])  # Update end-effector position\n",
    "\n",
    "        return pred_line, true_line, ee_line\n",
    "\n",
    "    # Create the animation using FuncAnimation\n",
    "    ani = FuncAnimation(\n",
    "        fig,\n",
    "        update,  # Update function\n",
    "        frames=traj.shape[0],  # Number of frames (steps in the trajectory)\n",
    "        init_func=init,  # Initialization function\n",
    "        blit=True,  # Use blitting for better performance\n",
    "        interval=50,  # Interval between frames in milliseconds\n",
    "        repeat=False  # Do not repeat the animation\n",
    "    )\n",
    "\n",
    "    plt.close(fig)  # Close the figure to prevent it from displaying as a static plot\n",
    "    return HTML(ani.to_html5_video())  # Return the animation as an HTML video\n",
    "\n",
    "# Create the animation and display it\n",
    "animation = create_animation(traj, gr_true, ee_pos)\n",
    "animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Inference Time Cuda: 0.549 ms\n",
      "Std Inference Time Cuda: 0.008 ms\n",
      "Mean Inference Time Cpu: 1.366 ms\n",
      "Std Inference Time Cpu: 0.817 ms\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "\n",
    "# Number of warm-up iterations (not measured for timing)\n",
    "num_warmup = 5\n",
    "\n",
    "# Number of measured iterations (used for timing)\n",
    "num_measure = 10\n",
    "\n",
    "# List to store measured inference times\n",
    "times = []\n",
    "\n",
    "# Get a sample input and target from the dataset\n",
    "inputs, targets = dataset[idx]\n",
    "\n",
    "# Set the device to CUDA (GPU) for inference\n",
    "device = 'cuda'\n",
    "\n",
    "# Move inputs to the GPU and add a batch dimension\n",
    "inputs = inputs.to(device).unsqueeze(0)  # Shape: (1, num_markers, features)\n",
    "\n",
    "# Move targets to the GPU\n",
    "targets = targets.to(device).float()  # Shape: (num_markers, 2)\n",
    "\n",
    "# Move the model to the GPU\n",
    "model = model.to(device)\n",
    "\n",
    "# Measure inference time on GPU\n",
    "for i in range(num_warmup + num_measure):\n",
    "    # Synchronize CUDA to ensure accurate timing\n",
    "    torch.cuda.synchronize() if torch.cuda.is_available() else None\n",
    "\n",
    "    # Record the start time\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Perform inference without computing gradients\n",
    "    with torch.no_grad():\n",
    "        output = model(inputs)\n",
    "\n",
    "    # Synchronize CUDA again after inference\n",
    "    torch.cuda.synchronize() if torch.cuda.is_available() else None\n",
    "\n",
    "    # Record the end time\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Skip warm-up iterations and record measured times\n",
    "    if i >= num_warmup:\n",
    "        times.append(end_time - start_time)\n",
    "\n",
    "# Calculate mean and standard deviation of inference times on GPU\n",
    "mean_time = np.mean(times) * 1e3  # Convert to milliseconds\n",
    "std_time = np.std(times) * 1e3    # Convert to milliseconds\n",
    "print(f\"Mean Inference Time Cuda: {mean_time:.3f} ms\")\n",
    "print(f\"Std Inference Time Cuda: {std_time:.3f} ms\")\n",
    "\n",
    "# Set the device to CPU for inference\n",
    "device = 'cpu'\n",
    "\n",
    "# Move the model to the CPU\n",
    "model = model.to(device)\n",
    "\n",
    "# Move inputs to the CPU\n",
    "inputs = inputs.to(device)\n",
    "\n",
    "# Measure inference time on CPU\n",
    "for i in range(num_warmup + num_measure):\n",
    "    # Synchronize CUDA (if available) to ensure accurate timing\n",
    "    torch.cuda.synchronize() if torch.cuda.is_available() else None\n",
    "\n",
    "    # Record the start time\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Perform inference without computing gradients\n",
    "    with torch.no_grad():\n",
    "        output = model(inputs)\n",
    "\n",
    "    # Synchronize CUDA again after inference\n",
    "    torch.cuda.synchronize() if torch.cuda.is_available() else None\n",
    "\n",
    "    # Record the end time\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Skip warm-up iterations and record measured times\n",
    "    if i >= num_warmup:\n",
    "        times.append(end_time - start_time)\n",
    "\n",
    "# Calculate mean and standard deviation of inference times on CPU\n",
    "mean_time = np.mean(times) * 1e3  # Convert to milliseconds\n",
    "std_time = np.std(times) * 1e3    # Convert to milliseconds\n",
    "print(f\"Mean Inference Time Cpu: {mean_time:.3f} ms\")\n",
    "print(f\"Std Inference Time Cpu: {std_time:.3f} ms\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
